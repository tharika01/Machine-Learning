
# Machine Learning

Includes implementation of several Machine learning algorithhms.


## Install

 - [NumPy](https://numpy.org/)
 - [Pandas](http://pandas.pydata.org/)
 - [Matplotlib](https://matplotlib.org/)
 - [Scikit-learn](https://scikit-learn.org/stable/)

You will also need to have software installed to run and execute a [Jupyter Notebook](http://jupyter.org/install.html).

If you do not have Python installed yet, it is highly recommended that you install the [Anaconda](https://www.anaconda.com/download/) distribution of Python, which already has the above packages and more included. 

### Code

Code is provided in the respective folders along with the dataset used.

### Run

In a terminal or command window, navigate to the top-level project directory and run one of the following commands:

```bash
ipython notebook filename.ipynb
```  
or
```bash
jupyter notebook filename.ipynb
```

This will open the Jupyter Notebook software and project file in your browser.

# Supervised Learning
### Regression
- [Multiple Linear Regression](https://github.com/tharika01/Machine-Learning/blob/main/Regression/multiple_linear_regression.ipynb)
- [Polynomial regression](https://github.com/tharika01/Machine-Learning/blob/main/Regression/polynomial_regression.ipynb)
- [Support Vector Regression](https://github.com/tharika01/Machine-Learning/blob/main/Regression/support_vector_regression.ipynb)
- [Decision Tree regression](https://github.com/tharika01/Machine-Learning/blob/main/Regression/decision_tree_regression.ipynb)
- [Random Forest regression](https://github.com/tharika01/Machine-Learning/blob/main/Regression/random_forest_regression.ipynb)

### Classification

- [Logistic Regression](https://github.com/tharika01/Machine-Learning/blob/main/Classification/logistic_regression.ipynb)
- [K_Nearest Neighbors](https://github.com/tharika01/Machine-Learning/blob/main/Classification/knn.ipynb)
- [Support Vector Machine](https://github.com/tharika01/Machine-Learning/blob/main/Classification/svm.ipynb)
- [Kernal Support Vector Machine](https://github.com/tharika01/Machine-Learning/blob/main/Classification/kernal_svm.ipynb) (with hyper parameter tuning)
- [Naive Bayes](https://github.com/tharika01/Machine-Learning/blob/main/Classification/Naive_bayes.ipynb)
- [Decision Tree Classifier](https://github.com/tharika01/Machine-Learning/blob/main/Classification/Decision%20Tree%20Classification.ipynb)
- [Random Forest Classifier](https://github.com/tharika01/Machine-Learning/blob/main/Classification/Random%20Forest%20Classifier.ipynb)

Model was trained on all the  above classification on the same dataset, observed that kernal SVM and KNN yielded maximum accuracy of 93 %.

